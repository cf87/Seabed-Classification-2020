{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads KRAKEN data and returns, training, hold out validation, and test\n",
    "def load_dataset(idx, shuffle, Ntrain):\n",
    "    filepath = \"files_116/files_VLA_rand_\"+ str(idx) +\"_116.mat\"\n",
    "    \n",
    "    mat = scipy.io.loadmat(filepath)\n",
    "    signal_train=np.array([], dtype=np.float)\n",
    "  \n",
    "    # Training data\n",
    "    args = (mat['p_cl_n'], mat['p_si_n'], mat['p_sa_n'],mat['p_gr_n'])\n",
    "    for v in args: \n",
    "        tmp=np.vstack([np.real(v), np.imag(v)]) \n",
    "        signal_train=np.hstack([signal_train, tmp]) if signal_train.size else tmp\n",
    "\n",
    "    mats=[1500,  1575, 1650, 1800]\n",
    "    labels_train=np.array([mats[int(np.floor(i/1000))] for i in range(4000)], dtype=np.float)\n",
    "    \n",
    "    # Test data\n",
    "    signal_test=np.array([],dtype=np.float)\n",
    "    labels_test=np.array([], dtype=np.float)\n",
    "    \n",
    "    for j in range(10):\n",
    "        i=j+1\n",
    "        args=(mat[\"p_cl_n\"+str(i)], mat['p_si_n'+str(i)], mat[\"p_sa_n\"+str(i)], mat[\"p_gr_n\"+str(i)])\n",
    "        for v in args: \n",
    "            tmp=np.vstack([np.real(v), np.imag(v)])\n",
    "            signal_test=np.hstack([signal_test, tmp]) if signal_test.size else tmp\n",
    "\n",
    "        labels_test=np.real(np.append([labels_test], [labels_train]))\n",
    "\n",
    "    # Test labels are perturbed, associate them with the correct material type\n",
    "    Y=labels_test\n",
    "    labels=labels_test\n",
    "    \n",
    "    X = signal_train.transpose()\n",
    "    y = labels_train\n",
    "    X_test = signal_test.transpose()\n",
    "    y_test = Y\n",
    "    \n",
    "    X = signal_train.transpose()\n",
    "    y = labels_train\n",
    "    X_test = signal_test.transpose()\n",
    "    y_test = labels_test\n",
    "    \n",
    "   \n",
    "    ind=range(len(y))\n",
    "    ind_train=ind[1:Ntrain]\n",
    "    ind_val=ind[Ntrain:len(y)]\n",
    "    ind_test = range(len(y_test))\n",
    "\n",
    "  \n",
    "    if shuffle:\n",
    "        ind1 = np.random.permutation(len(y))\n",
    "        ind_train=ind1[0:Ntrain]\n",
    "        ind_val=ind1[Ntrain:len(y)]\n",
    "        ind_test = np.random.permutation(len(y_test))\n",
    "    \n",
    "    X_train = np.array(X[ind_train,:], dtype = np.float)\n",
    "    y_train = np.array(y[ind_train],)   \n",
    "    X_val = np.array(X[ind_val,:], dtype = np.float)\n",
    "    y_val = np.array(y[ind_val],) \n",
    "    X_test = np.array(X_test[ind_test,:], dtype = np.float)\n",
    "    y_test = np.array(y_test[ind_test],)  \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x130ed9d30>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the training and test data\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset(15,False, 3200)\n",
    "\n",
    "f, ax = plt.subplots(2, 2, sharey=False, sharex=False)\n",
    "ax[0][0].plot(X_train[:,4], color='orange')\n",
    "ax[0][1].plot(y_train, color='yellow')\n",
    "ax[1][0].plot(X_test[0:4000,20], color='green')\n",
    "ax[1][1].plot(y_test, color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Benchmark metrics for each classifier\n",
    "# Adapted from Peter Prettenhofer, et. al,\n",
    "# https://scikit-learn.org/0.19/auto_examples/text/document_classification_20newsgroups.html\n",
    "def benchmark(clf):\n",
    "    target_names=[]\n",
    "    targets=np.unique(y_train);\n",
    "\n",
    "    for i in range(len(targets)):\n",
    "        target_names.append(np.str(targets[i]))\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "    \n",
    "    results=clf.cv_results_\n",
    "    candidates = np.flatnonzero(results['rank_test_score'] == 1)\n",
    "    for candidate in candidates:\n",
    "        print(\"Model with rank: {0}\".format(1))\n",
    "        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\"\n",
    "              .format(results['mean_test_score'][candidate],\n",
    "                      results['std_test_score'][candidate]))\n",
    "        print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "        print(\"\\n\")\n",
    "    print(\"Validation: \")\n",
    "    pred=clf.predict(X_val)\n",
    "    test_time = time() - t0\n",
    "    #print(metrics.confusion_matrix(y_val, pred))\n",
    "    #print(metrics.classification_report(y_val, pred, target_names=target_names))\n",
    "    score = metrics.accuracy_score(y_val, pred)\n",
    "    print(\"val score:   %0.3f\" % score)\n",
    "    \n",
    "    print(\"Testing: \")\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "    \n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "    print(\"classification report:\")\n",
    "    #print(metrics.classification_report(y_test, pred, target_names=target_names))\n",
    "    print(\"confusion matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    clf_descr = str(str(clf.estimator))\n",
    "    clf_rep = str(metrics.classification_report(y_test, pred, target_names=target_names))\n",
    "    clf_cm = str(metrics.confusion_matrix(y_test, pred))\n",
    "    return clf_descr, score, train_time, test_time, clf_rep, clf_cm\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform, expon\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "\n",
    "\n",
    "# list of (estimator, param_dist), where param_dist is used  in RandomizedSearchCV\n",
    "classifiers = [\n",
    "#      (GaussianProcessClassifier(warm_start=True, n_jobs=-1, random_state=42),{\n",
    "#         'multi_class': [\"one_vs_rest\", \"one_vs_one\"],\n",
    "#         'n_restarts_optimizer':[0, 1]\n",
    "#      }),\n",
    "     (KNeighborsClassifier(), {\n",
    "         'n_neighbors': sp_randint(8, 10),\n",
    "         'weights': ['uniform', 'distance'],\n",
    "         'algorithm':['ball_tree', 'kd_tree'],\n",
    "     }),\n",
    "    (NearestCentroid(), {\n",
    "         'metric': ['euclidean', 'manhattan','minkowski','chebyshev'],\n",
    "         'shrink_threshold': [None, .001, .0001, .1, .01]\n",
    "     }),\n",
    "    (SVC(kernel='linear'), {\n",
    "        'C': np.logspace(-1, 3, 100),\n",
    "        'tol': np.logspace(-8, -2, 100)\n",
    "    }),\n",
    "    (SVC(random_state=42, gamma='scale'), {\n",
    "        'C': [.1, 1, 10, 100, 1000],\n",
    "        'kernel': ['rbf', 'poly', 'linear', 'sigmoid'], \n",
    "        'class_weight':['balanced', None],\n",
    "        'tol': np.logspace(-8, -2, 100)\n",
    "    }),\n",
    "    (MLPClassifier(max_iter=100000), {\n",
    "        'hidden_layer_sizes': [(200), (50), (100,)],\n",
    "        'alpha': expon(scale=.1),\n",
    "        'learning_rate': ['constant','adaptive'],\n",
    "    }),\n",
    "    (DecisionTreeClassifier(),{\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'splitter': ['best','random'],\n",
    "        'max_features':[None, 'auto', 'sqrt', 'log2'],\n",
    "    }),\n",
    "    (RandomForestClassifier(max_depth=5, n_jobs=-1), {\n",
    "        \"max_depth\": sp_randint(2, 20),\n",
    "        \"n_estimators\": sp_randint(2, 50),\n",
    "        \"max_features\": ['auto', 'log2'],\n",
    "        'class_weight': ['balanced', 'balanced_subsample'],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    }),\n",
    "     (GaussianNB(), {\n",
    "         'var_smoothing': np.logspace(-12, -8, 100)\n",
    "     }), \n",
    "     (LinearDiscriminantAnalysis(n_components=2), {\n",
    "         'solver': ['svd', 'lsqr'],\n",
    "         'tol': np.logspace(-10, -2, 100)\n",
    "     }),\n",
    "     (LogisticRegression(solver='newton-cg', random_state=0, max_iter=100000), {\n",
    "        'C': [.1, 1, 10, 100, 1000],\n",
    "         'multi_class': [\"auto\", \"ovr\",\"multinomial\"],\n",
    "         'solver': ['sag', 'saga', 'newton-cg'],\n",
    "         'tol': np.logspace(-6, -4, 100)\n",
    "     }),\n",
    "]\n",
    "names = [e.__class__.__name__ for e, g in classifiers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests the classifiers without hyperparameter search\n",
    "X_train, y_train,X_val, y_val, X_test, y_test= load_dataset(15, True, 3999)\n",
    "X_val=X_train\n",
    "y_val=y_train\n",
    "target_names=[]\n",
    "targets=np.unique(y_train);\n",
    "for i in range(len(targets)):\n",
    "        target_names.append(np.str(targets[i]))\n",
    "        \n",
    "\n",
    "j=1\n",
    "(clf, param_grid)=classifiers[j]\n",
    "name=names[j]\n",
    "print(name)\n",
    "clf.fit(X_train, y_train)\n",
    "pred=clf.predict(X_val)\n",
    "print(metrics.confusion_matrix(y_val, pred))\n",
    "#print(metrics.classification_report(y_val, pred, target_names=target_names))\n",
    "score = metrics.accuracy_score(y_val, pred)\n",
    "print(\"val score:   %0.3f\" % score)\n",
    "pred=clf.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "#print(metrics.classification_report(y_test, pred, target_names=target_names))\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"test score:   %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data_name=['KRAKEN 2 layer']\n",
    "dset_name=data_name\n",
    "\n",
    "noiselevel = np.array([15, 17 ,19, 21, 26, 30, 32 ,33, 60])\n",
    "grid_searches = [dict() for x in range(len(noiselevel))]\n",
    "results = [[] for x in range(len(noiselevel))]\n",
    "ds_cnt=-1\n",
    "for nl in noiselevel:\n",
    "    ds_cnt=ds_cnt+1\n",
    "    X_train, y_train,X_val, y_val, X_test, y_test= load_dataset(nl, True, 3200)\n",
    "    \n",
    "    print('\\n Noise level:', str(nl),'\\n')\n",
    "   \n",
    "    # iterate over classifiers\n",
    "    for est_idx, (name, (estimator, param_grid)) in \\\n",
    "        enumerate(zip(names, classifiers)):\n",
    "\n",
    "        # Perform randomized grid search over possible hyperparameters\n",
    "        clf = RandomizedSearchCV(estimator=estimator, param_distributions=param_grid, n_iter=20, cv=5,\n",
    "                                 verbose=0, n_jobs=-1)\n",
    "        \n",
    "        with ignore_warnings(category=ConvergenceWarning):\n",
    "            results[ds_cnt].append(benchmark(clf))\n",
    "        grid_searches[ds_cnt][name] = clf\n",
    "\n",
    "        # Make predictions for the four test cases\n",
    "        print(name)\n",
    "        \n",
    "        #print('Test Score', str(clf.score(X_test, y_test)))\n",
    "      \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# Displaying results to paste into latex\n",
    "for nc in range(9):\n",
    "    print(\"\\\\begin{filecontents}{\"+names[nc]+\"-kraken.dat}\\n noise \tsnr accuracy\") \n",
    "    for nl in range(len(noiselevel)):\n",
    "        clf_descr, score, train_time, test_time, clf_rep, clf_cm=results[nl][nc]\n",
    "    \n",
    "        print(str(noiselevel[nl])+\" \"+ str(18-nl)+\" \"+ str(score*100))\n",
    "    print(\"\\end{filecontents}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying results in a pandas dataframe\n",
    "#Code adapted from https://www.kaggle.com/grfiv4/displaying-the-results-of-a-grid-search\n",
    "import pandas as pd\n",
    "def score_summary(grid_searches, sort_by='mean_test_score'):\n",
    "        frames = []\n",
    "        for name, grid_search in grid_searches.items():\n",
    "            frame = pd.DataFrame(grid_search.cv_results_)\n",
    "            frame = frame.filter(regex='^(?!.*param_).*$')\n",
    "            frame['estimator'] = len(frame)*[name]\n",
    "            frames.append(frame)\n",
    "        df = pd.concat(frames)\n",
    "        \n",
    "        df = df.sort_values([sort_by], ascending=False)\n",
    "        df = df.reset_index()\n",
    "        df = df.drop(['rank_test_score', 'index'], 1)\n",
    "        \n",
    "        columns = df.columns.tolist()\n",
    "        columns.remove('estimator')\n",
    "        columns = ['estimator']+columns\n",
    "        df = df[columns]\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=score_summary(grid_searches[0])\n",
    "print(noiselevel[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
