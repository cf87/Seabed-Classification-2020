{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification, load_iris\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import h5py\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename, summary=False):\n",
    "    mat = scipy.io.loadmat(filename)\n",
    "    \n",
    "    test={}\n",
    "    \n",
    "    signal1=np.real(np.concatenate([mat['p_cl_n'], mat['p_si_n'],mat['p_sa_n'], mat['p_gr_n']],axis=1)).transpose()\n",
    "    signal2=np.imag(np.concatenate([mat['p_cl_n'], mat['p_si_n'],mat['p_sa_n'], mat['p_gr_n']],axis=1)).transpose()\n",
    "    signal=np.concatenate([signal1, signal2], axis=1)\n",
    "    for i in range(1,11):\n",
    "        aux1=np.real(np.concatenate([mat['p_cl_n'+str(i)], mat['p_si_n'+str(i)],mat['p_sa_n'+str(i)], mat['p_gr_n'+str(i)]],axis=1)).transpose()\n",
    "        aux2=np.imag(np.concatenate([mat['p_cl_n'+str(i)], mat['p_si_n'+str(i)],mat['p_sa_n'+str(i)], mat['p_gr_n'+str(i)]],axis=1)).transpose()\n",
    "        test[i]=np.concatenate([aux1, aux2], axis=1)\n",
    "    labels=np.array([int(np.floor(i/1000)) for i in range(4000)])\n",
    "    \n",
    "    \n",
    "    if summary:\n",
    "        N=4000\n",
    "        signal_mean=signal.mean(axis=1).reshape((N, 1))\n",
    "        signal_std=signal.std(axis=1).reshape((N, 1))\n",
    "        signal=np.concatenate((signal_mean, signal_std), axis=1)\n",
    "        for i in test.keys():\n",
    "            test_mean=test[i].mean(axis=1).reshape((N, 1))\n",
    "            test_std=test[i].std(axis=1).reshape((N, 1))\n",
    "            test[i]=np.concatenate((test_mean, test_std), axis=1)\n",
    "            \n",
    "\n",
    "    X = signal\n",
    "    y = labels\n",
    "    \n",
    "    all_testing=np.concatenate([test[i] for i in range(1,11)])\n",
    "    all_labels=np.concatenate([y for i in range(1,11)])\n",
    "    return X, y, all_testing, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1=\"./files_116/files_VLA_rand_15_116.mat\"\n",
    "f2=\"./files_116/files_VLA_rand_17_116.mat\"\n",
    "f3=\"./files_116/files_VLA_rand_19_116.mat\"\n",
    "f4=\"./files_116/files_VLA_rand_21_116.mat\"\n",
    "f5=\"./files_116/files_VLA_rand_26_116.mat\"\n",
    "f6=\"./files_116/files_VLA_rand_30_116.mat\"\n",
    "f7=\"./files_116/files_VLA_rand_32_116.mat\"\n",
    "f8=\"./files_116/files_VLA_rand_33_116.mat\"\n",
    "f9=\"./files_116/files_VLA_rand_60_116.mat\"\n",
    "filenames=[f1,f2,f3,f4,f5,f6,f7,f8,f9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train={}\n",
    "y_train={}\n",
    "X_test={}\n",
    "y_test={}\n",
    "for i in range(len(filenames)):\n",
    "    X_train[i],y_train[i],X_test[i], y_test[i] =load_dataset(filenames[i], False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "names = [\"LDA\",\"Nearest Neighbors\", \"Nearest Centroid\", \"Linear SVM\", \"RBF SVM\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Gaussian Process\", \"Neural Net\", ]#, \"AdaBoost\",\n",
    "#         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    KNeighborsClassifier(5),\n",
    "    NearestCentroid(metric='euclidean'),\n",
    "    SVC(kernel=\"linear\", gamma='auto'),\n",
    "    SVC(gamma='scale'),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    GaussianProcessClassifier(multi_class='one_vs_rest'), #1.0 * RBF(1.0)\n",
    "    MLPClassifier()] #(alpha=1, max_iter=1000),\n",
    "    #AdaBoostClassifier(),\n",
    "    #GaussianNB(),\n",
    "    #QuadraticDiscriminantAnalysis()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Process\n",
      "[[ 756  172   52   20]\n",
      " [ 168  699  136    0]\n",
      " [   0    0  957    1]\n",
      " [   0    0    0 1039]]\n"
     ]
    }
   ],
   "source": [
    "#1000 points per class (remove nothing)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "score=[]\n",
    "for name, clf in zip(names, classifiers):\n",
    "    if name=='Gaussian Process':\n",
    "        \n",
    "        X,y= shuffle(np.delete(X_train[0], [] ,axis=0), np.delete(y_train[0], [],axis=0))\n",
    "        clf.fit(X, y)\n",
    "        print(name)\n",
    "        #aux=[clf.score(X_test[i], y_test[i]) for i in range(len(filenames))]\n",
    "        #score = score+[aux]\n",
    "        #print(aux)\n",
    "        \n",
    "        X_t, y_t = shuffle(X_test[1], y_test[1])\n",
    "        conf = confusion_matrix(y_t[0:4000], clf.predict(X_t[0:4000]))\n",
    "        print(conf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Process\n",
      "[[ 899    0   73   28]\n",
      " [ 630    0  363    0]\n",
      " [   0    0 1011    1]\n",
      " [   0    0    0  995]]\n"
     ]
    }
   ],
   "source": [
    "#remove one point from second class\n",
    "from sklearn.metrics import confusion_matrix\n",
    "score=[]\n",
    "for name, clf in zip(names, classifiers):\n",
    "    if name=='Gaussian Process':\n",
    "        \n",
    "        X,y= shuffle(np.delete(X_train[0], [1005] ,axis=0), np.delete(y_train[0], [1005],axis=0))\n",
    "        clf.fit(X, y)\n",
    "        print(name)\n",
    "        #aux=[clf.score(X_test[i], y_test[i]) for i in range(len(filenames))]\n",
    "        #score = score+[aux]\n",
    "        #print(aux)\n",
    "        \n",
    "        X_t, y_t = shuffle(X_test[1], y_test[1])\n",
    "        conf = confusion_matrix(y_t[0:4000], clf.predict(X_t[0:4000]))\n",
    "        print(conf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
